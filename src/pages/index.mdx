---
layout: ../layouts/Layout.astro
title: "HocusPOCUS: An OOD benchmark for point-of-care-ultrasound"
description: An OOD benchmark for point-of-care-ultrasound 
favicon: favicon.svg
thumbnail: screenshot.png
---

import Layout from "../layouts/Layout.astro";

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";

import hocuspocus from "../assets/hocuspocus.svg";
import applications from "../assets/applications.svg";
import fig2 from "../assets/fig2_website.svg";
import fig3 from "../assets/fig3.svg";
import mf_shifts from "../assets/mf_shifts.svg";
import cov_factors_bg from "../assets/cov_factors-bg.svg";
import cov_factors_fg_shape from "../assets/cov_factors-fg_shape.svg";
import supplemental_video from "../assets/supplemental_video.gif";
import Splat from "../components/Splat.tsx"

import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Stanley Bryan Zamora Hua",
      url: "https://stan-hua.github.io/",
      institution: "The Hospital for Sick Children",
    },
    {
      name: "Lauren Erdman",
      institution: "Cincinnati Children's Hospital",
    },
  ]}
  conference="Pre-Print"
  links={[
    {
      name: "Paper",
      url: "",
      icon: "ri:file-pdf-2-line",
    },
    {
      name: "Code",
      url: "https://github.com/stan-hua/hocuspocus",
      icon: "ri:github-line",
    },
    {
      name: "arXiv",
      url: "",
      icon: "academicons:arxiv",
    },
    {
      name: "Zenodo",
      url: "https://zenodo.org/records/14941380",
      icon: "ri:database-2-line",
    },
    {
      name: "Kaggle",
      url: "https://www.kaggle.com/datasets/stanleyhua/hocuspocus-an-ood-benchmark-for-pocus/",
      icon: "ri:database-2-line",
    }
  ]}
  />

## The HocusPOCUS Benchmark

|                                         | **Description**                                        | **Train/Val/Test**  |
|-----------------------------------------|--------------------------------------------------------|---------------------|
| **HP-Atlas**  | POCUS videos from 11 distinct use-cases | 176/217/461 videos (48.7K images)  |
| **HP-Quality**        | Pairs of POCUS vs. non-POCUS images                    | 426/520/1154 images |
| **HP-Noise**               | Generated noisy images mimicking scanner-specific artifacts      | 480/480/960 images  |

<Figure>
    <Image source={hocuspocus} altText="HocusPOCUS Datasets" style="max-width: 100%; height: auto !important;" />
</Figure>

<HighlightedSection>

## TLDR;

Real-time machine learning for point-of-care ultrasound requires knowing ***when a model doesn't know*.
We introduce HocusPOCUS, a benchmark for detecting data shifts in realistic deployment scenarios.
Experiments on three clinical applications highlight the promise and existing limitations of using maximum logit score, baseline post-hoc method, to identify model failure under both semantic and covariate shift.
By addressing these challenges, OOD detection can enhance the reliability and trustworthiness of machine learning systems in dynamic real-world POCUS settings.
</HighlightedSection>


## üèÉ Quickstart

### Setup library
```python
% pip install hocuspocus_ood
from hocuspocus_ood import HocusPocusDataset, load_hocuspocus_metadata

# Define optional dataset parameters
hparams = {
    "transform": ...                # Torchvision transforms
    "load_image_func": ...,         # Custom calling function to load image given image path
    "load_image_kwargs": ...,       # Keyword arguments for custom image loading function
    "img_mode": 3,                  # 3 = RGB, 1 = Grayscale
    "img_size": (224, 224),         # Image size to resize to
    "scale": True,                  # If True, perform min-max normalization
}
```

### 1. Load HP-Atlas
```python
# Option 1. Both the extracted foreground and background are loaded
dataset = HocusPocusDataset("atlas", **hparams)
# Option 2. HP-Atlas dataset with background details kept
# dataset = HocusPocusDataset("atlas", separate_background=False, **hparams)
print(dataset[0])
# {
#   'id': 'pocus_atlas-renal-3-1',
#   'video_id': 'pocus_atlas-renal-3',
#   'img': ...,
#   'background_img': ...,
#   'label': 'renal',
# }
```

### 2. Load HP-Quality
```python
dataset = HocusPocusDataset("quality", **hparams)
print(dataset[0])
# {
#   'id': '0001-0',
#   'img': ...,
#   'label': 'thyroid',
#   'quality': 'low_quality',
# }
```

### 3. Load HP-Noise
```python
dataset = HocusPocusDataset("noise", **hparams)
print(dataset[0])
# {
#   'id': 'hp_noise-1',
#   'img': ...,
#   'label': 'noise-solid',
# }
```

<hr />


<HighlightedSection>
## üë©üèª‚Äç‚öïÔ∏è Clinical Applications
### 2D Ultrasound View Classification
- **Adult Knee** ([K-JoCo](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SKP9IB))
- **Maternal-Fetal** ([MF-Spain](https://zenodo.org/records/3904280), [MF-Africa](https://zenodo.org/records/7540448), MF-3 (Private))
- **Pediatric Renal** (PR-1 (Private), PR-2 (Private))

<Figure caption="">
    <Image source={applications} altText="Clinical Applications" style="max-width: 100% !important; height: auto !important;" />
</Figure>

</HighlightedSection>

<hr />

## üö® Key Findings

### üí°OOD Detection Can Identify Model Failure under Semantic and Covariate Shif
<Image source={fig2} altText="OOD Detection Identifies Model Failure under Semantic and Covariate Shift" style="max-width: 100% !important; height: auto !important;" />

> Majority of unseen views (among held-out datasets and HocusPOCUS) are identified as (semantically) OOD.
> Among covariate-shifted data `MF-Spain` to `MF-Africa` and `PR-1` to `PR-2`, detection identifies correctly-predicted examples.

**NOTE**: Threshold is determined by validation data in source domain and HocusPOCUS datasets.


### ‚ö†Ô∏è Caveat 1. Disambiguating Failure between Semantic vs. Covariate Shift Detection is Manual and Requires Domain Expertise.

<Image source={mf_shifts} altText="MF-3 images are more semantically shifted than only covariately shifted." style="max-width: 50% !important; height: auto !important;" />
> Unlike `MF-Spain`/`MF-Africa`, `MF-3` images are captured in the 1st trimester much earlier and are very different both in appearance and common pathologies observed.
> OOD detection seemingly fails to identify correctly-predicted samples (77\% accuracy).
> However, with clinician collaborators, we identify that the shift from 2nd/3rd trimester versus 1st trimester more closely matches a semantic shift, and thus should be identified as semantically OOD.



### ‚ö†Ô∏è Caveat 2. Detection Can Amplify Model Biases
<Image source={fig3} altText="OOD Detection Identifies Model Failure under Semantic and Covariate Shift" style="max-width: 100% !important; height: auto !important;" />

> **(a)** More severe disease manifestations are identified as outliers (K-JoCo: osteoarthritis, PR-1/PR-2: hydronephrosis) despite little effect on model performance. Bars (left-axis) indicate percentage identified as outliers, while points (right-axis) indicate accuracy gap between inliers and outliers.

> **(b)** OOD worsens label imbalance among identified inliers, particularly in the imbalanced setting. Smallest/Largest refer to the least/most represented class in each dataset.

> **(c)** OOD can marginally worsen label balance in the balanced setting.


### ‚ö†Ô∏è Caveat 3. Detection is Affected by Spurious Scanner-Specific Covariates
<TwoColumns>
  <Figure slot="left">
    <Image source={cov_factors_bg} altText="OOD Detection is affected by scanner-specific background details" style="max-width: 100 !important%; height: auto !important;" />
  </Figure>
  <Figure slot="right">
    <Image source={cov_factors_fg_shape} altText="OOD Detection is affected by probe-specific foreground shape" style="max-width: 100% !important; height: auto !important;" />
  </Figure>
</TwoColumns>


### ‚ö†Ô∏è Caveat 4. MLS is not ready for real-time OOD detection
<Figure caption="Example (Lung) POCUS Video">
  <Image source={supplemental_video} altText="Example (Lung) POCUS Video" style="max-width: 50% !important; height: auto !important;" />
</Figure>

<Table>
  | Metric       | Adult Knee | Maternal-Fetal | Pediatric Renal |
  |--------------|------------|----------------|-----------------|
  | AUROC (Max Intra-Video Score)    | 99%       | 75.8%          | 66.6%           |
  | AUROC (Min Intra-Video Score)    | 89.6%      | 48.7%          | 37.4%           |
</Table>

<hr />

## BibTeX citation

```bibtex
@misc{...,
  author = "{Stanley Bryan Zamora Hua, ..., Lauren Erdman}",
  title = "HocusPOCUS: A OOD benchmark for point-of-care ultrasound",
  year = "2025",
  howpublished = "\url{...}",
}
```